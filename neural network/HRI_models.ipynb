{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZUUttcm1Y9Q",
        "outputId": "d47ca92b-fe67-43fd-cf75-fd295efd0885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TGZwQyY6-oBw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Customize a dataset for a fusion model\n",
        "class FusionDataset():\n",
        "    def __init__(self, csv_file_X, csv_file_y, hr_file, transform=transform, target_transform=None):\n",
        "        self.openface_X = np.load(csv_file_X)\n",
        "        self.openface_label = np.load(csv_file_y)\n",
        "        self.hr_file = pd.read_csv(hr_file)\n",
        "        self.lstm_length = lstm_length\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.openface_X[idx,:len(self.openface_X)-1]\n",
        "        image = torch.tensor(image, dtype=torch.float)\n",
        "        labels = self.openface_label\n",
        "        labels = torch.tensor(labels, dtype=torch.float)\n",
        "\n",
        "        hr = self.hr_file.iloc[idx, 1:self.lstm_length+1]\n",
        "        hr = torch.Tensor(hr)\n",
        "        hr = torch.unsqueeze(hr, 0)\n",
        "        hr_label = self.hr_file.iloc[idx, 1]\n",
        "        hr_label = torch.tensor(hr_label, dtype=torch.float)\n",
        "        hr_label = torch.unsqueeze(hr_label, 0)\n",
        "        \n",
        "        return image, labels, hr, hr_label"
      ],
      "metadata": {
        "id": "b6lfblJ1Vww7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "3xOdbX6ST07p"
      },
      "outputs": [],
      "source": [
        "#Customize a dataset for an openface model\n",
        "class OFDataset():\n",
        "    def __init__(self, csv_file_X, csv_file_y):\n",
        "        self.openface_X = np.load(csv_file_X)\n",
        "        self.openface_label = np.load(csv_file_y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.openface_X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.openface_X[idx,:len(self.openface_X)-1]\n",
        "        image = torch.tensor(image, dtype=torch.float)\n",
        "        labels = self.openface_label\n",
        "        labels = torch.tensor(labels, dtype=torch.float)\n",
        "        \n",
        "        return image, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Customize a dataset for a cnn model\n",
        "class ImageDataset():\n",
        "    def __init__(self, csv_file_X, csv_file_y):\n",
        "        self.openface_X = np.load(csv_file_X)\n",
        "        self.openface_label = np.load(csv_file_y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.openface_X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.openface_X[idx,:len(self.openface_X)-1]\n",
        "        image = torch.tensor(image, dtype=torch.float)\n",
        "        labels = self.openface_label\n",
        "        labels = torch.tensor(labels, dtype=torch.float)\n",
        "        \n",
        "        return image, labels"
      ],
      "metadata": {
        "id": "tTrPUSRIDh0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HObwCBtkZ0k-"
      },
      "outputs": [],
      "source": [
        "#Customize a dataset for an heart rate model\n",
        "class HRDataset():\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, lstm_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.hr_file = pd.read_csv(csv_file)\n",
        "        self.lstm_length = lstm_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        hr = self.hr_file.iloc[idx, 1:self.lstm_length+1]\n",
        "        hr = torch.Tensor(hr)\n",
        "        hr = torch.unsqueeze(hr, 0)\n",
        "        label = self.hr_file.iloc[idx, 0]\n",
        "        label = torch.tensor(label, dtype=torch.float)\n",
        "\n",
        "        return hr, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "l0FTH798T-4F"
      },
      "outputs": [],
      "source": [
        "#Split heart rate data into training set and test set and generate two dataloaders respectively\n",
        "lstm_length = 10\n",
        "data_HR = HRDataset('/content/drive/MyDrive/HRItest/HRI HR_update.csv', lstm_length)\n",
        "HR_training_data, HR_test_data = train_test_split(data_HR, test_size=0.33, random_state=42)\n",
        "batch_size = 20\n",
        "HR_train_dataloader = DataLoader(HR_training_data, batch_size=batch_size, shuffle=True)\n",
        "HR_test_dataloader = DataLoader(HR_test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "r2pPB1jiDLg0"
      },
      "outputs": [],
      "source": [
        "#Split openface data into training set and test set and generate two dataloaders respectively\n",
        "data_of = OFDataset('/content/drive/MyDrive/HRItest/X.npy', '/content/drive/MyDrive/HRItest/y.npy')\n",
        "training_data, test_data = train_test_split(data_of, test_size=0.33, random_state=42)\n",
        "batch_size = 20\n",
        "of_train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "of_test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into training set and test set for a fusion model and generate two dataloaders respectively\n",
        "lstm_length = 10\n",
        "data = FusionDataset('/content/drive/MyDrive/HRItest/X.npy', '/content/drive/MyDrive/HRItest/y.npy','/content/drive/MyDrive/HRItest/HRI HR_update.csv', lstm_length)\n",
        "training_data, test_data = train_test_split(data, test_size=0.33, random_state=42)\n",
        "batch_size = 20\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "pAW_s_sNWjE_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "37CQxcBmZlQE"
      },
      "outputs": [],
      "source": [
        "#Build a neural network for openface data\n",
        "class OFNet(torch.nn.Module):\n",
        "  def __init__(self,size):\n",
        "      super(OFNet, self).__init__()\n",
        "      self.size = size\n",
        "      self.new_layers = torch.nn.Sequential(torch.nn.Linear(self.size, 1))\n",
        "                                      \n",
        "  def forward(self, x):\n",
        "      x = self.new_layers(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kyzyVHsAGGUi"
      },
      "outputs": [],
      "source": [
        "#Build a LSTM network for a fusion model\n",
        "class Lstm(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        #self.fc   = torch.nn.Linear(hidden_size, output_size)\n",
        "        self.fc = torch.nn.Sequential(torch.nn.Linear(hidden_size, 100),\n",
        "                                           torch.nn.ReLU(),\n",
        "                                           torch.nn.Linear(100, output_size))\n",
        "        \n",
        "    def forward(self, x):\n",
        "   \n",
        "        out,_ = self.lstm(x)           # out.shape = (batch_size, seq_len, hidden_size)\n",
        "        out = out.view(-1, self.hidden_size) # out.shape = (seq_len, hidden_size)     \n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a LSTM network for a non-fusion model\n",
        "class Lstm_only(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc   = torch.nn.Linear(hidden_size, output_size)\n",
        "        #self.fc = torch.nn.Sequential(torch.nn.Linear(hidden_size, 100),\n",
        "                                           #torch.nn.ReLU(),\n",
        "                                           #torch.nn.Linear(100, output_size))\n",
        "        \n",
        "    def forward(self, x):\n",
        "   \n",
        "        out,_ = self.lstm(x)           # out.shape = (batch_size, seq_len, hidden_size)\n",
        "        out = out.view(-1, self.hidden_size) # out.shape = (seq_len, hidden_size)     \n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "0JVq6KIwN9W-"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "09JiwjW2_8OE"
      },
      "outputs": [],
      "source": [
        "#Build a MLP for a fusion model\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self,size):\n",
        "      super(Net, self).__init__()\n",
        "      self.size = size\n",
        "      self.new_layers = torch.nn.Sequential(torch.nn.Linear(self.size, 2))\n",
        "                                          \n",
        "  def forward(self, x):\n",
        "      x = self.new_layers(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "uqsQe1bcVSB9"
      },
      "outputs": [],
      "source": [
        "#Train a LSTM model\n",
        "def lstm_train(model, epochs, train_dataloader, valid_data=None, lr=0.001, print_every=100):\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    train_loss = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        #hs = None\n",
        "        t_loss = 0\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "\n",
        "            lstm_inputs, lstm_labels = data\n",
        "\n",
        "            opt.zero_grad()\n",
        "            \n",
        "            # Create batch_size dimension\n",
        "            #x = x.unsqueeze(0)\n",
        "            #print(lstm_inputs.shape,lstm_labels.shape)\n",
        "            #print(lstm_inputs.shape)\n",
        "            out = model(lstm_inputs)\n",
        "            \n",
        "            \n",
        "            loss = criterion(out, lstm_labels)\n",
        "            #print(out.shape,lstm_labels.shape)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            t_loss += loss.item()\n",
        "            \n",
        "            \n",
        "        train_loss.append(np.mean(t_loss))\n",
        "            \n",
        "            \n",
        "        if epoch % print_every == 0:\n",
        "            print(f'Epoch {epoch}:\\nTraining Loss: {train_loss[-1]}')\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a LSTM for fusion model\n",
        "def lstm_train_fusion(model, epochs, train_dataloader, valid_data=None, lr=0.001, print_every=100):\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    opt = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    train_loss = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        #hs = None\n",
        "        t_loss = 0\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "\n",
        "            _,_,lstm_inputs, lstm_labels = data\n",
        "\n",
        "            opt.zero_grad()\n",
        "            \n",
        "            # Create batch_size dimension\n",
        "            #x = x.unsqueeze(0)\n",
        "            #print(lstm_inputs.shape,lstm_labels.shape)\n",
        "            #print(lstm_inputs.shape)\n",
        "            out = model(lstm_inputs)\n",
        "            \n",
        "            \n",
        "            loss = criterion(out, lstm_labels)\n",
        "            #print(out.shape,lstm_labels.shape)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            t_loss += loss.item()\n",
        "            \n",
        "            \n",
        "        train_loss.append(np.mean(t_loss))\n",
        "            \n",
        "            \n",
        "        if epoch % print_every == 0:\n",
        "            print(f'Epoch {epoch}:\\nTraining Loss: {train_loss[-1]}')\n",
        "            "
      ],
      "metadata": {
        "id": "M9jk8SK7xxPt"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "PktGBXvvESXZ"
      },
      "outputs": [],
      "source": [
        "##Train a openface model\n",
        "def OF_train(model, epochs, train_dataloader, valid_data=None, lr=0.001, print_every=100):\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    train_loss = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        hs = None\n",
        "        t_loss = 0\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            \n",
        "            features, labels = data\n",
        "            #print(features.shape,labels.shape)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Create batch_size dimension\n",
        "            #x = x.unsqueeze(0)\n",
        "            \n",
        "            output = model(features)\n",
        "            #print(output.shape)\n",
        "            #print(output.shape,labels.shape)\n",
        "            #hs = tuple([h.data for h in hs])\n",
        "            \n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            t_loss += loss.item()\n",
        "            \n",
        "            \n",
        "        train_loss.append(np.mean(t_loss))\n",
        "            \n",
        "            \n",
        "        if epoch % print_every == 0:\n",
        "            print(f'Epoch {epoch}:\\nTraining Loss: {train_loss[-1]}')\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train a openface model for fusion model\n",
        "def OF_train_fusion(model, epochs, train_dataloader, valid_data=None, lr=0.001, print_every=100):\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    train_loss = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        hs = None\n",
        "        t_loss = 0\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            \n",
        "            features, labels,_,_ = data\n",
        "            #print(features.shape,labels.shape)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Create batch_size dimension\n",
        "            #x = x.unsqueeze(0)\n",
        "            \n",
        "            output = model(features)\n",
        "            #print(output.shape)\n",
        "            #print(output.shape,labels.shape)\n",
        "            #hs = tuple([h.data for h in hs])\n",
        "            \n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            t_loss += loss.item()\n",
        "            \n",
        "            \n",
        "        train_loss.append(np.mean(t_loss))\n",
        "            \n",
        "            \n",
        "        if epoch % print_every == 0:\n",
        "            print(f'Epoch {epoch}:\\nTraining Loss: {train_loss[-1]}')\n",
        "            "
      ],
      "metadata": {
        "id": "Iq5pfZin-gbX"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "txFZDBWmHLwV"
      },
      "outputs": [],
      "source": [
        "#Train fusion model\n",
        "def net_train(model, epochs, train_dataloader, valid_data=None, lr=0.001, print_every=100):\n",
        "\n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    train_loss = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        hs = None\n",
        "        t_loss = 0\n",
        "        for i, data in enumerate(train_dataloader, 0):\n",
        "            \n",
        "            features, labels = data[:-1],data[-1]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Create batch_size dimension\n",
        "            #x = x.unsqueeze(0)\n",
        "            \n",
        "            output = net(features)\n",
        "            #print(output.shape,labels.shape)\n",
        "            #hs = tuple([h.data for h in hs])\n",
        "            \n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            t_loss += loss.item()\n",
        "            \n",
        "            \n",
        "        train_loss.append(np.mean(t_loss))\n",
        "        \n",
        "        #t_loss += loss.item()    \n",
        "            \n",
        "        if epoch % print_every == 0:\n",
        "            print(f'Epoch {epoch}:\\nTraining Loss: {train_loss[-1]}')\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "kdDwpCJeGbsB"
      },
      "outputs": [],
      "source": [
        "lstm = Lstm(input_size=lstm_length, hidden_size=1000, num_layers=1, output_size=1)\n",
        "lstm_only = Lstm(input_size=lstm_length, hidden_size=1000, num_layers=1, output_size=1)\n",
        "imagenet = OFNet(size=710)\n",
        "net = Net(size=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OF_train(imagenet, 1000, of_train_dataloader, valid_data=None, lr=0.001, print_every=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO4QMoZuQ1Xo",
        "outputId": "f70525bd-02d0-4880-a71a-75ada4deb708"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([20, 1065])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([13, 1065])) that is different to the input size (torch.Size([13, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "Training Loss: 121685.419090271\n",
            "Epoch 100:\n",
            "Training Loss: 768.8558168411255\n",
            "Epoch 200:\n",
            "Training Loss: 378.87736415863037\n",
            "Epoch 300:\n",
            "Training Loss: 44009.89278411865\n",
            "Epoch 400:\n",
            "Training Loss: 561.7428703308105\n",
            "Epoch 500:\n",
            "Training Loss: 306.3523836135864\n",
            "Epoch 600:\n",
            "Training Loss: 341.476957321167\n",
            "Epoch 700:\n",
            "Training Loss: 305.29329109191895\n",
            "Epoch 800:\n",
            "Training Loss: 631.6449089050293\n",
            "Epoch 900:\n",
            "Training Loss: 375.36213397979736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_train(lstm, 1000, HR_train_dataloader, lr=0.0005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYvU7ozqHJJr",
        "outputId": "a0e40d08-9a4f-48af-dd19-f8d45a2bae5a"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([18])) that is different to the input size (torch.Size([18, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "Training Loss: 83.33154296875\n",
            "Epoch 100:\n",
            "Training Loss: 17.216050148010254\n",
            "Epoch 200:\n",
            "Training Loss: 16.96065902709961\n",
            "Epoch 300:\n",
            "Training Loss: 17.15447187423706\n",
            "Epoch 400:\n",
            "Training Loss: 17.407597541809082\n",
            "Epoch 500:\n",
            "Training Loss: 16.903281211853027\n",
            "Epoch 600:\n",
            "Training Loss: 16.97908115386963\n",
            "Epoch 700:\n",
            "Training Loss: 17.1210355758667\n",
            "Epoch 800:\n",
            "Training Loss: 17.031180381774902\n",
            "Epoch 900:\n",
            "Training Loss: 17.240516662597656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_train_fusion(lstm_only, 1000, train_dataloader, lr=0.0005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFLViuegRvWJ",
        "outputId": "fe012a8f-19b7-4214-d980-5f1c5df33eea"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "Training Loss: 23130.96142578125\n",
            "Epoch 100:\n",
            "Training Loss: 2008.9101993589118\n",
            "Epoch 200:\n",
            "Training Loss: 1033.2977653987966\n",
            "Epoch 300:\n",
            "Training Loss: 696.5815197321466\n",
            "Epoch 400:\n",
            "Training Loss: 525.9162960794204\n",
            "Epoch 500:\n",
            "Training Loss: 423.26029957970695\n",
            "Epoch 600:\n",
            "Training Loss: 354.6298524425698\n",
            "Epoch 700:\n",
            "Training Loss: 305.488964826315\n",
            "Epoch 800:\n",
            "Training Loss: 268.37545576693486\n",
            "Epoch 900:\n",
            "Training Loss: 239.52854514577643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5k0eOW9KuAg",
        "outputId": "f152346b-baba-4073-b411-b630fea0128a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "#Save train models\n",
        "PATH = './HRI_net.pth'\n",
        "torch.save(lstm_only.state_dict(), PATH)\n",
        "lstm_only.load_state_dict(torch.load(PATH))\n",
        "PATH = './HRI_net.pth'\n",
        "torch.save(imagenet.state_dict(), PATH)\n",
        "imagenet.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the test loss for lstm model\n",
        "criterion = torch.nn.MSELoss()\n",
        "t_loss = 0\n",
        "with torch.no_grad():\n",
        "    for data in HR_test_dataloader:\n",
        "        features, labels = data\n",
        "        net_outputs = lstm(features)\n",
        "        loss = torch.sqrt(criterion(net_outputs, labels))\n",
        "        #t_loss += loss.item()\n",
        "\n",
        "    print('test_loss:',loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXozg6oUTMgi",
        "outputId": "1314fda7-c43b-4315-8bbb-67001646513d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss: tensor(6.5750)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute the test loss for openface model\n",
        "criterion = torch.nn.MSELoss()\n",
        "t_loss = 0\n",
        "with torch.no_grad():\n",
        "    for data in of_test_dataloader:\n",
        "        features, labels = data\n",
        "        net_outputs = imagenet(features)\n",
        "        loss = torch.sqrt(criterion(net_outputs, labels))\n",
        "        t_loss += loss.item()\n",
        "\n",
        "    print('test_loss:',np.mean(t_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ykwhQdxT9gJ",
        "outputId": "b9179ba9-83cf-4e5e-b592-d2ee97bd3e30"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss: 623.2139301300049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([20, 1065])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([12, 1065])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "_EualmY8K9LJ"
      },
      "outputs": [],
      "source": [
        "#Generate a new dataset for fusion model\n",
        "hs = None\n",
        "dataset = None\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        inputs, labels, lstm_inputs, lstm_labels = data\n",
        "        \n",
        "        image_outputs = imagenet(inputs)\n",
        "        lstm_outputs = lstm(lstm_inputs)\n",
        "        \n",
        "        \n",
        "        #features = torch.cat((torch.cat((cnn_outputs, torch.squeeze((lstm_outputs),1)), 1),torch.unsqueeze(labels,1)),1)\n",
        "        features = torch.cat((image_outputs, lstm_outputs),1)\n",
        "        if dataset is None:\n",
        "          dataset = features\n",
        "        else:\n",
        "          dataset = torch.cat((dataset, features), 0)\n",
        "       \n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "Psrw5p0tW1oR"
      },
      "outputs": [],
      "source": [
        "training_data_pred, test_data_pred = train_test_split(dataset, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vJlAdo9GbPP",
        "outputId": "77339a72-cf3c-4fb3-d5af-92f74dfeb992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "Training Loss: 0.011692415064317174\n",
            "Epoch 100:\n",
            "Training Loss: 0.008945544684604444\n",
            "Epoch 200:\n",
            "Training Loss: 0.008779892735553326\n",
            "Epoch 300:\n",
            "Training Loss: 0.008626589869756717\n",
            "Epoch 400:\n",
            "Training Loss: 0.00847910259864916\n",
            "Epoch 500:\n",
            "Training Loss: 0.008335780462878079\n",
            "Epoch 600:\n",
            "Training Loss: 0.008195885988202908\n",
            "Epoch 700:\n",
            "Training Loss: 0.008058986601874816\n",
            "Epoch 800:\n",
            "Training Loss: 0.00792479847479519\n"
          ]
        }
      ],
      "source": [
        "net_train(net, 900, training_data_pred, lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7315-c3f-Qd",
        "outputId": "ab9b11b8-33a4-424a-b06f-59ff2ffc9bfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "PATH = './HRI_net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "net.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THt4pFxqf6HA",
        "outputId": "6c3a32c5-23cb-4293-974f-81e06bd60b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss: 0.18427092395722866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "#Compute the test loss for fusion model\n",
        "criterion = torch.nn.MSELoss()\n",
        "t_loss = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_data_pred:\n",
        "        features, labels = data[:-1],data[-1]\n",
        "        net_outputs = net(features)\n",
        "        loss = torch.sqrt(criterion(net_outputs, labels))\n",
        "        t_loss += loss.item()\n",
        "\n",
        "    print('test_loss:',np.mean(t_loss))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HRI models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}